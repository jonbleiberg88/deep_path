# WSI Segmentation with Deep Learning

Code for Kluger Lab project to classify bone marrow tissue into large and small cell tumors and normal tissue using CNNs. (Work in progress)

## Requirements:

* Python 3.6 or higher
* Numpy
* PIL
* matplotlib
* tensorflow
* OpenSlide

Openslide can be installed by following the instructions at https://openslide.org/download/.  All
other libraries can be installed via pip.

## Mode 1: Training a Model from pre-Annotated Data:

**Assumptions**:  The library assumes that the user has available a collection of whole-slide images (WSIs) whose region
of interests have been annotated using the open source program QuPath.

### Extracting annotations from QuPath

**Usage**: The user first open their qpproj file encompassing their annotations. If certain naming conventions are followed, the `create_qupath_proj.py` script can be used to create the qpproj file. Next,
run the `extract_qupath_data.groovy` script from QuPath's automation interface. Doing so will generate a folder for each slide containing CSV files with the coordinates of that slide's annotations as well as a folder containing CSV files with the surface area of each annotated region.

### Extracting patches from WSI's

**Usage**: `python3 construct_training_dataset`

**Description**: Creates a dataset of patches from the slides.  

**Relevant Constants**:

	* `SLIDE_FILE_DIRECTORY`
	* `SLIDE_FILE_EXTENSION`
	* `PATCH_OUTPUT_DIRECTORY`
	* `ANNOTATION_CSV_DIRECTORY`

### Model Tuning

**Usage**: `python3.6 train_classifier.py`.  Trains a classifier and compiles basic metrics on accuracy and loss. Outputs trained model files to `MODEL_FILE_FOLDER` found in `constants.py`.

**Description**:  Retrains a pre-trained model (ex. Inceptionv3, ResNet50) to classify patches of
whole-slide images.  To better evaluate the robustness of the model, the script will train k models, each with a different
train-test split.  Train/test data split are determined as in k-fold cross validation.  A good starting point is k = 5
giving a train/test ratio of 80%/20%.

**Relevant Constants**:

	* `NUM_FOLDS`
	* `TFHUB_MODULE`
	* `HOW_MANY_TRAINNG_STEPS`
	* `RANDOM_CROP`
	* `RANDOM_SCALE`
	* `RANDOM_BRIGHTNESS`
	* `FLIP_LEFT_RIGHT`
	* `MODEL_FILE_FOLDER`
	* `INPUT_LAYER`
	* `OUTPUT_LAYER`
	* `TEST_SLIDE_FOLDER`
	* `TEST_SLIDE_LIST`

### Model Training and Prediction (Leave One Out CV)

**Usage**: `python3.6 predict_patch_classes.py`

**Description**: Trains a classifier and generates predictions for
each patient using the a model trained on the other patients. Outputs predictions to the
`PREDICTIONS_DIRECTORY` defined in `constants.py` for downstream visualization. Generates basic
evaluation metrics.


### Model Evaluation and Visualization

**Usage**: `python3 generate_slide_predictions.py`

**Description**: Compiles and aggregates predictions generated by `predict_patch_classes.py` to
generate final evaluation metrics. Creates a visualization for each patient with the
patch prediction confidences overlayed on a thumbnail of the original slide images.

**Relevant Constants**:

**Example**:

## Visualization Tools

### Histograms

**Usage**: `python3 draw_histograms.py`.  Outputs PNG files in the directory `HISTOGRAM_FOLDER` as specified in `constants.py`.

**Description**: Display the relative frequencies of patches for each test patient classified as positive by the network for a given fold.

**Relevant Constants**:

	* `POS_SLIDE_CONFIDENCE_LISTS`
	* `NEG_SLIDE_CONFIDENCE_LISTS`
	* `HISTOGRAM_FOLDER`
	* `HISTOGRAM_SUBFOLDER`

**Example**:

<img align="center" src="https://raw.githubusercontent.com/ethanweinberger/deep_path/master/example_images/pos_histogram_composite.png"/>
<img align="center" src="https://raw.githubusercontent.com/ethanweinberger/deep_path/master/example_images/neg_histogram_composite.png"/>

### Composite ROC Curve

**Usage**: `python3 draw_kfold_roc_curve.py`. Outputs PNG file in the directory from which the script is run.

**Description**: Computes ROC curves for each of the k trained networks.  Displays these as well as averages them into a
single curve with accompanying error bars.


**Relevant Constants**:

	* `FOLD_VOTE_CONTAINER_LISTS_PATH`

**Example**:

<img align="center" src="https://raw.githubusercontent.com/ethanweinberger/deep_path/master/example_images/k-fold_roc.png"/>

### Patch Visualizer

**Usage**: `python3 patch_visualizer.py --which_fold = placeholder_fold_number`.  Output displays in new window, patches
can be scrolled through using arrow keys, as well as number keys to jump to the corresponding decile (ex. hitting 4
goes to the 40th percentile).  Hitting the '-' key moves to the slide with the highest confidence.  

**Description**: Displays patches for test patients in a given fold.  Patches are shown with their confidence value
for being classified as positive.

**Relevant Constants**:

	* `CONFIDENCE_CONTAINER_LIST`

**Example**:

<img align="center" src="https://raw.githubusercontent.com/ethanweinberger/deep_path/master/example_images/patch_visualizer_example.png"/>

### Confidence Heatmaps

**Usage**: `python3 view_confidence_heatmaps.py --which_fold = placeholder_fold_number`.  Output displays in a new window,
slides can be scrolled through using arrow keys.

**Description**: Overlays heatmaps onto whole slide image thumbnails describing the confidence of patches being classified
as positive.

**Relevant Constants**:

	* `PATCH_NAME_TO_COORDS_MAP`
	* `SLIDE_NAME_TO_TILE_DIMS_MAP`
	* `SLIDE_NAME_TO_PATCHES_MAP`
	* `PATCH_NAME_TO_CONFIDENCE_MAP`
	* `TEST_SLIDE_FOLDER`
	* `TEST_SLIDE_LIST`
	* `SLIDE_FILE_DIRECTORY`

**Example**:

<img align="center" src="https://raw.githubusercontent.com/ethanweinberger/deep_path/master/example_images/heatmap_example.png"/>
